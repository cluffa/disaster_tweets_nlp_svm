<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="author: Alex Cluff" />


<title>Disaster Tweets</title>

<script src="index_files/header-attrs-2.11/header-attrs.js"></script>
<script src="index_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="index_files/navigation-1.1/tabsets.js"></script>
<script src="index_files/navigation-1.1/codefolding.js"></script>
<link href="index_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="index_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Disaster Tweets</h1>
<h4 class="author">author: Alex Cluff</h4>
<h4 class="date">(last edit 2022-02-10 10:52:43)</h4>

</div>


<p>This is project to introduce myself to NLP in R.</p>
<p>With Kaggle disaster tweets dataset:</p>
<p><a href="https://www.kaggle.com/c/nlp-getting-started">Natural Language Processing with Disaster Tweets | Kaggle</a></p>
<pre class="r"><code>tweets &lt;- read_csv(&#39;./train.csv&#39;, show_col_types = FALSE)
glimpse(tweets)</code></pre>
<pre><code>## Rows: 7,613
## Columns: 5
## $ id       &lt;dbl&gt; 1, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24,…
## $ keyword  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ location &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ text     &lt;chr&gt; &quot;Our Deeds are the Reason of this #earthquake May ALLAH Forgi…
## $ target   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0…</code></pre>
<pre class="r"><code>mean(tweets$target)</code></pre>
<pre><code>## [1] 0.4296598</code></pre>
<p>This is close enough to 0.5 that I will still use an accuracy score. If it becomes a problem I might use f1 score.</p>
<p>I will use object type corpus from the tm package to process the data. A corpus is a collection of text style character strings or documents.</p>
<pre class="r"><code>Corpus(VectorSource(tweets$text))</code></pre>
<pre><code>## &lt;&lt;SimpleCorpus&gt;&gt;
## Metadata:  corpus specific: 1, document level (indexed): 0
## Content:  documents: 7613</code></pre>
<pre class="r"><code># using tm package

preprocess_tweets &lt;- function(text, prob = 0.999, extra_blacklist = c()) {
  # bag of words style encoding
  # removes sparse words
  # input char vector of tweets, prob, extra words to remove
  
  # words to remove
  blacklist &lt;- c( 
    stopwords(&quot;english&quot;),
    &#39;û&#39;,
    extra_blacklist)
  
  text %&gt;% 
    VectorSource() %&gt;%                  # makes a vector input formatted for corpus()
    Corpus() %&gt;%                        # creates list of documents called a corpus
    tm_map(PlainTextDocument) %&gt;%       # converts to plain text
    tm_map(tolower) %&gt;%                 # makes all lowercase
    tm_map(removePunctuation) %&gt;%       # remove punctuation
    tm_map(removeWords, blacklist) %&gt;%  # remove blacklisted words
    tm_map(stemDocument) %&gt;%            # combine stem words, ex: jumping/jumped
    DocumentTermMatrix() %&gt;%            # converts to binary matrix
    removeSparseTerms(prob) %&gt;%         # keeps top 99.9% or specified % of words
    as.matrix() %&gt;%
    as.tibble() %&gt;% 
    suppressWarnings() %&gt;% 
    return()
}</code></pre>
<p>I will use the same function on text, keyword, and location to make it simple. This adds 100s of new predictors to use depending on how many sparse words I remove.</p>
<pre class="r"><code>n &lt;- nrow(tweets)
test &lt;- read_csv(&#39;./test.csv&#39;, show_col_types = FALSE)

all_tweets &lt;- bind_rows(tweets, test)

x_text &lt;- preprocess_tweets(all_tweets$text)
x_location &lt;- preprocess_tweets(all_tweets$location, 0.9995)
x_keyword &lt;- preprocess_tweets(all_tweets$keyword, 0.9999)

names(x_text) &lt;- paste0(&#39;text_&#39;, names(x_text))
names(x_location) &lt;- paste0(&#39;location_&#39;, names(x_location))
names(x_keyword) &lt;- paste0(&#39;keyword_&#39;, names(x_keyword))

y_target &lt;- tweets$target

# only for use in kaggle predictions
test_x_text &lt;- x_text[(n + 1):nrow(all_tweets),]
test_x_location &lt;- x_location[(n + 1):nrow(all_tweets),]
test_x_keyword &lt;- x_keyword[(n + 1):nrow(all_tweets),]

x_text &lt;- x_text[1:n,]
x_location &lt;- x_location[1:n,]
x_keyword &lt;- x_keyword[1:n,]</code></pre>
<pre class="r"><code>tweets$text[1:4]</code></pre>
<pre><code>## [1] &quot;Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all&quot;                                                                
## [2] &quot;Forest fire near La Ronge Sask. Canada&quot;                                                                                               
## [3] &quot;All residents asked to &#39;shelter in place&#39; are being notified by officers. No other evacuation or shelter in place orders are expected&quot;
## [4] &quot;13,000 people receive #wildfires evacuation orders in California&quot;</code></pre>
<pre class="r"><code>x_text[1:4, 1:10]</code></pre>
<pre><code>## # A tibble: 4 × 10
##   text_earthquak text_may text_reason text_canada text_fire text_forest
##            &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1              1        1           1           0         0           0
## 2              0        0           0           1         1           1
## 3              0        0           0           0         0           0
## 4              0        0           0           0         0           0
## # … with 4 more variables: text_near &lt;dbl&gt;, text_ask &lt;dbl&gt;, text_evacu &lt;dbl&gt;,
## #   text_expect &lt;dbl&gt;</code></pre>
<p>Splitting into validation and training sets.</p>
<pre class="r"><code>train_group &lt;- sample(c(TRUE, FALSE), length(y_target), replace = TRUE, prob = c(0.75, 0.25))

train_x_text &lt;- x_text[train_group,]
train_x_location &lt;- x_location[train_group,]
train_x_keyword &lt;- x_keyword[train_group,]

valid_x_text &lt;- x_text[!train_group,]
valid_x_location &lt;- x_location[!train_group,]
valid_x_keyword &lt;- x_keyword[!train_group,]

train_y &lt;- y_target[train_group]
valid_y &lt;- y_target[!train_group]</code></pre>
<p>Testing accuracy with inclusion of different text fields and cost with linear svm.</p>
<pre class="r"><code>train_x &lt;- list(text = train_x_text, keyword = train_x_keyword, location = train_x_location)
valid_x &lt;- list(text = valid_x_text, keyword = valid_x_keyword, location = valid_x_location)

c_grid &lt;- c(0.1, 1, 10)
trys &lt;- list(
  c(T, F, F),
  c(T, F, T),
  c(T, T, F),
  c(T, T, T)
)
options &lt;- c(&#39;text&#39;, &#39;keyword&#39;, &#39;location&#39;)

results &lt;- data.frame()

combinations &lt;- length(c_grid)*length(trys)
j = 0
for (i in trys) {
  for (c in c_grid) {
    svm &lt;- svm(x = bind_cols(train_x[i]), y = train_y, type = &#39;C&#39;, kernel = &#39;linear&#39;, cost = c, scale = FALSE)
    pred_y &lt;- predict(svm, newdata = bind_cols(valid_x[i]))
    accuracy &lt;- mean(pred_y == valid_y)
    results &lt;- bind_rows(results, data.frame(accuracy = accuracy, cost = c, text = i[1], keyword = i[2], location = i[3]))
    
    j = j + 1
    print(paste0(as.character(j), &#39;/&#39;, combinations, &#39; completed&#39;))
  }
}</code></pre>
<pre><code>## [1] &quot;1/12 completed&quot;
## [1] &quot;2/12 completed&quot;
## [1] &quot;3/12 completed&quot;
## [1] &quot;4/12 completed&quot;
## [1] &quot;5/12 completed&quot;
## [1] &quot;6/12 completed&quot;
## [1] &quot;7/12 completed&quot;
## [1] &quot;8/12 completed&quot;
## [1] &quot;9/12 completed&quot;
## [1] &quot;10/12 completed&quot;
## [1] &quot;11/12 completed&quot;
## [1] &quot;12/12 completed&quot;</code></pre>
<pre class="r"><code>results %&gt;% arrange(desc(accuracy))</code></pre>
<pre><code>##     accuracy cost text keyword location
## 1  0.7856064  0.1 TRUE    TRUE    FALSE
## 2  0.7851032  0.1 TRUE    TRUE     TRUE
## 3  0.7800705  1.0 TRUE   FALSE    FALSE
## 4  0.7800705  0.1 TRUE   FALSE     TRUE
## 5  0.7795672  0.1 TRUE   FALSE    FALSE
## 6  0.7770508  1.0 TRUE   FALSE     TRUE
## 7  0.7770508  1.0 TRUE    TRUE    FALSE
## 8  0.7760443  1.0 TRUE    TRUE     TRUE
## 9  0.7579265 10.0 TRUE   FALSE    FALSE
## 10 0.7544036 10.0 TRUE    TRUE    FALSE
## 11 0.7468546 10.0 TRUE   FALSE     TRUE
## 12 0.7367891 10.0 TRUE    TRUE     TRUE</code></pre>
<p>A model trained on text and keywords with cost at 0.1 performed the best with an accuracy of 0.7856.</p>
<pre class="r"><code>train_x &lt;- bind_cols(train_x_text, train_x_keyword)
valid_x &lt;- bind_cols(valid_x_text, valid_x_keyword)
svm &lt;- svm(x = train_x, y = train_y, type = &#39;C&#39;, kernel = &#39;linear&#39;, cost = 0.1, scale = FALSE)
pred_y &lt;- predict(svm, newdata = valid_x) %&gt;% as.character() %&gt;% as.integer()</code></pre>
<pre class="r"><code>mean(pred_y) # % of positive predictions</code></pre>
<pre><code>## [1] 0.3301459</code></pre>
<p>There definitely is some bias in predictions. It skews towards “not disaster” much like the training data. The predictions were 33% disasters and the training data had 43%. Depending on the application, I could alter the training data to represent each category equally. This can be done with either sampling or removing non disaster tweets until categories are equal.</p>
<pre class="r"><code>data.frame(
  predictions = pred_y,
  actual = valid_y
) %&gt;% 
  group_by(predictions) %&gt;% 
  summarise(real_0 = mean(actual == 0), real_1 = mean(actual == 1))</code></pre>
<pre><code>## # A tibble: 2 × 3
##   predictions real_0 real_1
##         &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1           0  0.778  0.222
## 2           1  0.200  0.800</code></pre>
<p>78% of non-disaster tweets were correctly labeled and 80% of disaster tweets were correctly labeled.</p>
<p>There are a few things I may want to do in the future:<br />
1. fill out the rest of the keywords<br />
2. fill out locations with places in text<br />
3. work with the links<br />
4. use tweets being replied to</p>
<p>Fit on all data.</p>
<pre class="r"><code>x &lt;- bind_rows(train_x, valid_x)
y &lt;- c(train_y, valid_y)
svm &lt;- svm(x = x, y = y, type = &#39;C&#39;, kernel = &#39;linear&#39;, cost = 0.1, scale = FALSE)</code></pre>
<p>Predicting test data target.</p>
<pre class="r"><code>pred_submit &lt;- predict(svm, newdata = bind_cols(test_x_text, test_x_keyword))
head(data.frame(prediction = pred_submit, text = test$text), 10)</code></pre>
<pre><code>##    prediction
## 1           1
## 2           1
## 3           1
## 4           1
## 5           1
## 6           1
## 7           0
## 8           0
## 9           0
## 10          0
##                                                                                                text
## 1                                                                Just happened a terrible car crash
## 2                                  Heard about #earthquake is different cities, stay safe everyone.
## 3  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all
## 4                                                          Apocalypse lighting. #Spokane #wildfires
## 5                                                     Typhoon Soudelor kills 28 in China and Taiwan
## 6                                                                We&#39;re shaking...It&#39;s an earthquake
## 7                          They&#39;d probably still show more life than Arsenal did yesterday, eh? EH?
## 8                                                                                 Hey! How are you?
## 9                                                                                  What a nice hat?
## 10                                                                                        Fuck off!</code></pre>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
